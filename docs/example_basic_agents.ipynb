{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ReferentialGym\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_config = {\n",
    "    \"observability\":            \"full\",\n",
    "    \"max_sentence_length\":      10,\n",
    "    \"nbr_communication_round\":  1,\n",
    "    \"nbr_distractors\":          127,\n",
    "    \"distractor_sampling\":      \"uniform\",\n",
    "    \"descriptive\":              False,\n",
    "    \"object_centric\":           False,\n",
    "    \"nbr_stimulus\":             1,\n",
    "\n",
    "    \"graphtype\":                'straight_through_gumbel_softmax', #'reinforce'/'gumbel_softmax'/'straight_through_gumbel_softmax' \n",
    "    \"tau\":                      0.2,\n",
    "    \"vocab_size\":               20,\n",
    "\n",
    "    \"cultural_pressure_it_period\": 100,\n",
    "    \"cultural_substrate_size\":  5,\n",
    "    \n",
    "    \"batch_size\":               128,\n",
    "    \"dataloader_num_worker\":    8,\n",
    "    \n",
    "    \"learning_rate\":            1e-3,\n",
    "    \"adam_eps\":                 1e-5,\n",
    "    \"gradient_clip\":            5,\n",
    "\n",
    "    \"use_cuda\":                 True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_config = dict()\n",
    "speaker_config['nbr_distractors'] = 0 if rg_config['observability'] == \"partial\" else rg_config['nbr_distractors']\n",
    "speaker_config['nbr_stimulus'] = rg_config['nbr_stimulus']\n",
    "\n",
    "# Assuming CNN task:\n",
    "#speaker_config['observation_resize_dim'] = 64\n",
    "# Assuming FC task:\n",
    "#speaker_config['preprocess_function'] = 'PreprocessFunction'\n",
    "\n",
    "# Recurrent Convolutional Architecture:\n",
    "speaker_config['cnn_encoder_channels'] = [32, 32, 64]\n",
    "speaker_config['cnn_encoder_kernels'] = [6, 4, 3]\n",
    "speaker_config['cnn_encoder_strides'] = [6, 2, 1]\n",
    "speaker_config['cnn_encoder_paddings'] = [0, 1, 1]\n",
    "speaker_config['cnn_encoder_feature_dim'] = 512\n",
    "speaker_config['cnn_encoder_mini_batch_size'] = 128\n",
    "speaker_config['temporal_encoder_nbr_hidden_units'] = 512\n",
    "speaker_config['temporal_encoder_nbr_rnn_layers'] = 1\n",
    "speaker_config['temporal_encoder_mini_batch_size'] = 128\n",
    "speaker_config['symbol_processing_nbr_hidden_units'] = 512\n",
    "speaker_config['symbol_processing_nbr_rnn_layers'] = 2\n",
    "\n",
    "import copy\n",
    "listener_config = copy.deepcopy(speaker_config)\n",
    "listener_config['nbr_distractors'] = rg_config['nbr_distractors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReferentialGym.agents import BasicCNNSpeaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "nbr_distractors = speaker_config['nbr_distractors']\n",
    "nbr_stimulus = speaker_config['nbr_stimulus']\n",
    "obs_shape = [nbr_distractors+1,nbr_stimulus,1,28,28]\n",
    "feature_dim = 512\n",
    "vocab_size = rg_config['vocab_size']\n",
    "max_sentence_length = rg_config['max_sentence_length']\n",
    "\n",
    "bspeaker = BasicCNNSpeaker(kwargs=speaker_config, \n",
    "                              obs_shape=obs_shape, \n",
    "                              feature_dim=feature_dim, \n",
    "                              vocab_size=vocab_size, \n",
    "                              max_sentence_length=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\\nst_size = stimuli.size()\\nprint(st_size)\\ny_logits, y_one_hot = bspeaker(stimuli, multi_round=True)\\nprint(y_logits.size())\\n\\nnext_y_logits, next_y_one_hot = bspeaker(stimuli, \\n                                         sentences=y_one_hot, \\n                                         graphtype='straight_through_gumbel_softmax', \\n                                         multi_round=True)\\nprint(next_y_logits.size())\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\n",
    "st_size = stimuli.size()\n",
    "print(st_size)\n",
    "y_logits, y_one_hot = bspeaker(stimuli, multi_round=True)\n",
    "print(y_logits.size())\n",
    "\n",
    "next_y_logits, next_y_one_hot = bspeaker(stimuli, \n",
    "                                         sentences=y_one_hot, \n",
    "                                         graphtype='straight_through_gumbel_softmax', \n",
    "                                         multi_round=True)\n",
    "print(next_y_logits.size())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Listener:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReferentialGym.agents import BasicCNNListener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "nbr_distractors = listener_config['nbr_distractors']\n",
    "nbr_stimulus = listener_config['nbr_stimulus']\n",
    "obs_shape = [nbr_distractors+1,nbr_stimulus,1,28,28]\n",
    "feature_dim = 512\n",
    "vocab_size = rg_config['vocab_size']\n",
    "max_sentence_length = rg_config['max_sentence_length']\n",
    "\n",
    "blistener = BasicCNNListener(kwargs=listener_config, \n",
    "                              obs_shape=obs_shape, \n",
    "                              feature_dim=feature_dim, \n",
    "                              vocab_size=vocab_size, \n",
    "                              max_sentence_length=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\\nst_size = stimuli.size()\\nprint(st_size)\\n#y_logits, y_one_hot = bspeaker(stimuli)\\nprint(y_logits.size())\\ndecision_logits, next_sentences_logits, next_sentences = blistener(sentences=y_logits, \\n                                                                   stimuli=stimuli, \\n                                                                   graphtype='straight_through_gumbel_softmax',\\n                                                                   multi_round=True)\\nprint(decision_logits)\\nprint(next_sentences.size())\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\n",
    "st_size = stimuli.size()\n",
    "print(st_size)\n",
    "#y_logits, y_one_hot = bspeaker(stimuli)\n",
    "print(y_logits.size())\n",
    "decision_logits, next_sentences_logits, next_sentences = blistener(sentences=y_logits, \n",
    "                                                                   stimuli=stimuli, \n",
    "                                                                   graphtype='straight_through_gumbel_softmax',\n",
    "                                                                   multi_round=True)\n",
    "print(decision_logits)\n",
    "print(next_sentences.size())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = torchvision.datasets.MNIST(root='./datasets/', train=True, transform=None, target_transform=None, download=True)\n",
    "dataset = torchvision.datasets.MNIST(root='./datasets/', train=True, transform=T.ToTensor(), target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#notebook\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.imshow(dataset[0][0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReferentialGym.datasets import LabeledDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = {\n",
    "    \"dataset_class\":            \"LabeledDataset\",\n",
    "    \"dataset\":                  dataset,\n",
    "    \"nbr_stimulus\":             rg_config['nbr_stimulus'],\n",
    "    \"nbr_distractors\":          rg_config['nbr_distractors'],\n",
    "}\n",
    "\n",
    "dataset_mnistrg = LabeledDataset(kwargs=dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = dataset_mnistrg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f30348c6908>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(T.ToPILImage()(st[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3034856d30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(T.ToPILImage()(st[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t [0, 0, 0]\n",
      "1 \t [1, 0, 0]\n",
      "2 \t [0, 1, 0]\n",
      "3 \t [1, 1, 0]\n",
      "4 \t [0, 1, 1]\n",
      "5 \t [1, 1, 1]\n",
      "6 \t [0, 0, 1]\n",
      "7 \t [1, 0, 1]\n",
      "[4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "size = 2\n",
    "distractors = 2\n",
    "result = [0 for _ in range(distractors+1)]\n",
    "for idx in range( int(math.pow(size,distractors+1))):\n",
    "    indices = [0 for _ in range(distractors+1)]\n",
    "    idx2reduce = idx\n",
    "    for item_idx in reversed(range(distractors+1)):\n",
    "        exponant = item_idx\n",
    "        outof = int(math.pow(size, exponant)) \n",
    "        if outof > idx2reduce: continue\n",
    "        remainder = (idx2reduce//outof) % size \n",
    "        indices[item_idx] = remainder\n",
    "        idx2reduce -= size\n",
    "    print(idx,'\\t', indices)\n",
    "    result = [ r+i for i,r in zip(indices, result)]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referential Game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_class': 'LabeledDataset', 'dataset': Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./datasets/\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None, 'nbr_stimulus': 1, 'nbr_distractors': 127}\n"
     ]
    }
   ],
   "source": [
    "dataset_args = {\n",
    "    \"dataset_class\":            \"LabeledDataset\",\n",
    "    \"dataset\":                  dataset,\n",
    "    \"nbr_stimulus\":             rg_config['nbr_stimulus'],\n",
    "    \"nbr_distractors\":          rg_config['nbr_distractors'],\n",
    "}\n",
    "\n",
    "print(dataset_args)\n",
    "refgame = ReferentialGym.make(config=rg_config, dataset_args=dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "logger = SummaryWriter('./example_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 538.00 MiB (GPU 0; 5.93 GiB total capacity; 1.75 GiB already allocated; 57.75 MiB free; 41.80 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4bfff9ecc62f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mnbr_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbr_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m               verbose_period=100)\n\u001b[0m",
      "\u001b[0;32m~/Development/git/ReferentialGym/ReferentialGym/referential_game.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, prototype_speaker, prototype_listener, nbr_epoch, logger, verbose_period)\u001b[0m\n\u001b[1;32m     93\u001b[0m                                                                           \u001b[0mgraphtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'graphtype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                                                                           \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                                                                           multi_round=multi_round)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     decision_logits, listener_sentences_logits, listener_sentences = listener(sentences=speaker_sentences, \n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/git/ReferentialGym/ReferentialGym/agents/speaker.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, stimuli, sentences, graphtype, tau, multi_round)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimuli\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstimuli_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mnext_sentences_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'gumbel_softmax'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/git/ReferentialGym/ReferentialGym/agents/basic_cnn_speaker.py\u001b[0m in \u001b[0;36m_utter\u001b[0;34m(self, features, sentences)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Utter the next sentences:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mhiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;31m# (batch_size, 1, kwargs['symbol_processing_nbr_hidden_units'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_tf_final_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 522\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 538.00 MiB (GPU 0; 5.93 GiB total capacity; 1.75 GiB already allocated; 57.75 MiB free; 41.80 MiB cached)"
     ]
    }
   ],
   "source": [
    "refgame.train(prototype_speaker=bspeaker, \n",
    "              prototype_listener=blistener, \n",
    "              nbr_epoch=nbr_epoch,\n",
    "              logger=logger,\n",
    "              verbose_period=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
