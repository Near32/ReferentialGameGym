{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ReferentialGym\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_config = {\n",
    "    \"observability\":            \"full\",\n",
    "    \"max_sentence_length\":      10,\n",
    "    \"nbr_communication_round\":  1,\n",
    "    \"nbr_distractors\":          127,\n",
    "    \"distractor_sampling\":      \"uniform\",\n",
    "    \"descriptive\":              False,\n",
    "    \"object_centric\":           False,\n",
    "    \"nbr_stimulus\":             1,\n",
    "\n",
    "    \"graphtype\":                'straight_through_gumbel_softmax', #'reinforce'/'gumbel_softmax'/'straight_through_gumbel_softmax' \n",
    "    \"tau\":                      0.2,\n",
    "    \"vocab_size\":               20,\n",
    "\n",
    "    \"cultural_pressure_period\": 2,\n",
    "    \"cultural_substrate_size\":  5,\n",
    "    \n",
    "    \"batch_size\":               128,\n",
    "    \"dataloader_num_worker\":    8,\n",
    "    \n",
    "    \"learning_rate\":            1e-3,\n",
    "    \"adam_eps\":                 1e-5,\n",
    "    \"gradient_clip\":            5,\n",
    "\n",
    "    \"use_cuda\":                 True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_config = dict()\n",
    "speaker_config['nbr_distractors'] = 0 if rg_config['observability'] == \"partial\" else rg_config['nbr_distractors']\n",
    "speaker_config['nbr_stimulus'] = rg_config['nbr_stimulus']\n",
    "\n",
    "# Assuming CNN task:\n",
    "#speaker_config['observation_resize_dim'] = 64\n",
    "# Assuming FC task:\n",
    "#speaker_config['preprocess_function'] = 'PreprocessFunction'\n",
    "\n",
    "# Recurrent Convolutional Architecture:\n",
    "speaker_config['cnn_encoder_channels'] = [32, 32, 64]\n",
    "speaker_config['cnn_encoder_kernels'] = [6, 4, 3]\n",
    "speaker_config['cnn_encoder_strides'] = [6, 2, 1]\n",
    "speaker_config['cnn_encoder_paddings'] = [0, 1, 1]\n",
    "speaker_config['cnn_encoder_feature_dim'] = 512\n",
    "speaker_config['cnn_encoder_mini_batch_size'] = 128\n",
    "speaker_config['temporal_encoder_nbr_hidden_units'] = 512\n",
    "speaker_config['temporal_encoder_nbr_rnn_layers'] = 1\n",
    "speaker_config['temporal_encoder_mini_batch_size'] = 128\n",
    "speaker_config['symbol_processing_nbr_hidden_units'] = 512\n",
    "speaker_config['symbol_processing_nbr_rnn_layers'] = 2\n",
    "\n",
    "import copy\n",
    "listener_config = copy.deepcopy(speaker_config)\n",
    "listener_config['nbr_distractors'] = rg_config['nbr_distractors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReferentialGym.agents import BasicCNNSpeaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "nbr_distractors = speaker_config['nbr_distractors']\n",
    "nbr_stimulus = speaker_config['nbr_stimulus']\n",
    "obs_shape = [nbr_distractors+1,nbr_stimulus,1,28,28]\n",
    "feature_dim = 512\n",
    "vocab_size = rg_config['vocab_size']\n",
    "max_sentence_length = rg_config['max_sentence_length']\n",
    "\n",
    "bspeaker = BasicCNNSpeaker(kwargs=speaker_config, \n",
    "                              obs_shape=obs_shape, \n",
    "                              feature_dim=feature_dim, \n",
    "                              vocab_size=vocab_size, \n",
    "                              max_sentence_length=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\\nst_size = stimuli.size()\\nprint(st_size)\\ny_logits, y_one_hot = bspeaker(stimuli, multi_round=True)\\nprint(y_logits.size())\\n\\nnext_y_logits, next_y_one_hot = bspeaker(stimuli, \\n                                         sentences=y_one_hot, \\n                                         graphtype='straight_through_gumbel_softmax', \\n                                         multi_round=True)\\nprint(next_y_logits.size())\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\n",
    "st_size = stimuli.size()\n",
    "print(st_size)\n",
    "y_logits, y_one_hot = bspeaker(stimuli, multi_round=True)\n",
    "print(y_logits.size())\n",
    "\n",
    "next_y_logits, next_y_one_hot = bspeaker(stimuli, \n",
    "                                         sentences=y_one_hot, \n",
    "                                         graphtype='straight_through_gumbel_softmax', \n",
    "                                         multi_round=True)\n",
    "print(next_y_logits.size())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Listener:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReferentialGym.agents import BasicCNNListener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "nbr_distractors = listener_config['nbr_distractors']\n",
    "nbr_stimulus = listener_config['nbr_stimulus']\n",
    "obs_shape = [nbr_distractors+1,nbr_stimulus,1,28,28]\n",
    "feature_dim = 512\n",
    "vocab_size = rg_config['vocab_size']\n",
    "max_sentence_length = rg_config['max_sentence_length']\n",
    "\n",
    "blistener = BasicCNNListener(kwargs=listener_config, \n",
    "                              obs_shape=obs_shape, \n",
    "                              feature_dim=feature_dim, \n",
    "                              vocab_size=vocab_size, \n",
    "                              max_sentence_length=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\\nst_size = stimuli.size()\\nprint(st_size)\\n#y_logits, y_one_hot = bspeaker(stimuli)\\nprint(y_logits.size())\\ndecision_logits, next_sentences_logits, next_sentences = blistener(sentences=y_logits, \\n                                                                   stimuli=stimuli, \\n                                                                   graphtype='straight_through_gumbel_softmax',\\n                                                                   multi_round=True)\\nprint(decision_logits)\\nprint(next_sentences.size())\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stimuli = torch.zeros((batch_size,nbr_distractors+1,nbr_stimulus,1,28,28))\n",
    "st_size = stimuli.size()\n",
    "print(st_size)\n",
    "#y_logits, y_one_hot = bspeaker(stimuli)\n",
    "print(y_logits.size())\n",
    "decision_logits, next_sentences_logits, next_sentences = blistener(sentences=y_logits, \n",
    "                                                                   stimuli=stimuli, \n",
    "                                                                   graphtype='straight_through_gumbel_softmax',\n",
    "                                                                   multi_round=True)\n",
    "print(decision_logits)\n",
    "print(next_sentences.size())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = torchvision.datasets.MNIST(root='./datasets/', train=True, transform=None, target_transform=None, download=True)\n",
    "dataset = torchvision.datasets.MNIST(root='./datasets/', train=True, transform=T.ToTensor(), target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#notebook\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.imshow(dataset[0][0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReferentialGym.datasets import LabeledDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = {\n",
    "    \"dataset_class\":            \"LabeledDataset\",\n",
    "    \"dataset\":                  dataset,\n",
    "    \"nbr_stimulus\":             rg_config['nbr_stimulus'],\n",
    "    \"nbr_distractors\":          rg_config['nbr_distractors'],\n",
    "}\n",
    "\n",
    "dataset_mnistrg = LabeledDataset(kwargs=dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = dataset_mnistrg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1, 1, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe35cd38978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(T.ToPILImage()(st[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe35cccbda0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(T.ToPILImage()(st[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t [0, 0, 0]\n",
      "1 \t [1, 0, 0]\n",
      "2 \t [0, 1, 0]\n",
      "3 \t [1, 1, 0]\n",
      "4 \t [0, 1, 1]\n",
      "5 \t [1, 1, 1]\n",
      "6 \t [0, 0, 1]\n",
      "7 \t [1, 0, 1]\n",
      "[4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "size = 2\n",
    "distractors = 2\n",
    "result = [0 for _ in range(distractors+1)]\n",
    "for idx in range( int(math.pow(size,distractors+1))):\n",
    "    indices = [0 for _ in range(distractors+1)]\n",
    "    idx2reduce = idx\n",
    "    for item_idx in reversed(range(distractors+1)):\n",
    "        exponant = item_idx\n",
    "        outof = int(math.pow(size, exponant)) \n",
    "        if outof > idx2reduce: continue\n",
    "        remainder = (idx2reduce//outof) % size \n",
    "        indices[item_idx] = remainder\n",
    "        idx2reduce -= size\n",
    "    print(idx,'\\t', indices)\n",
    "    result = [ r+i for i,r in zip(indices, result)]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referential Game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_class': 'LabeledDataset', 'dataset': Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./datasets/\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None, 'nbr_stimulus': 1, 'nbr_distractors': 32}\n"
     ]
    }
   ],
   "source": [
    "dataset_args = {\n",
    "    \"dataset_class\":            \"LabeledDataset\",\n",
    "    \"dataset\":                  dataset,\n",
    "    \"nbr_stimulus\":             rg_config['nbr_stimulus'],\n",
    "    \"nbr_distractors\":          rg_config['nbr_distractors'],\n",
    "}\n",
    "\n",
    "print(dataset_args)\n",
    "refgame = ReferentialGym.make(config=rg_config, dataset_args=dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "logger = SummaryWriter('./example_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :: Iteration 0/469 :: Training/Loss = 3.496526002883911\n",
      "Epoch 0 :: Iteration 1/469 :: Training/Loss = 3.4965245723724365\n",
      "Epoch 0 :: Iteration 2/469 :: Training/Loss = 3.4965708255767822\n",
      "Epoch 0 :: Iteration 3/469 :: Training/Loss = 3.4963111877441406\n",
      "Epoch 0 :: Iteration 4/469 :: Training/Loss = 3.496523857116699\n",
      "Epoch 0 :: Iteration 5/469 :: Training/Loss = 3.496436357498169\n",
      "Epoch 0 :: Iteration 6/469 :: Training/Loss = 3.49646258354187\n",
      "Epoch 0 :: Iteration 7/469 :: Training/Loss = 3.4966022968292236\n",
      "Epoch 0 :: Iteration 8/469 :: Training/Loss = 3.496436834335327\n",
      "Epoch 0 :: Iteration 9/469 :: Training/Loss = 3.496523380279541\n",
      "Epoch 0 :: Iteration 10/469 :: Training/Loss = 3.496467113494873\n",
      "Epoch 0 :: Iteration 11/469 :: Training/Loss = 3.496385335922241\n",
      "Epoch 0 :: Iteration 12/469 :: Training/Loss = 3.4964966773986816\n",
      "Epoch 0 :: Iteration 13/469 :: Training/Loss = 3.496558666229248\n",
      "Epoch 0 :: Iteration 14/469 :: Training/Loss = 3.4965789318084717\n",
      "Epoch 0 :: Iteration 15/469 :: Training/Loss = 3.4964866638183594\n",
      "Epoch 0 :: Iteration 16/469 :: Training/Loss = 3.4964208602905273\n",
      "Epoch 0 :: Iteration 17/469 :: Training/Loss = 3.496570348739624\n",
      "Epoch 0 :: Iteration 18/469 :: Training/Loss = 3.4963223934173584\n",
      "Epoch 0 :: Iteration 19/469 :: Training/Loss = 3.4964497089385986\n",
      "Epoch 0 :: Iteration 20/469 :: Training/Loss = 3.4965031147003174\n",
      "Epoch 0 :: Iteration 21/469 :: Training/Loss = 3.4965803623199463\n",
      "Epoch 0 :: Iteration 22/469 :: Training/Loss = 3.496501922607422\n",
      "Epoch 0 :: Iteration 23/469 :: Training/Loss = 3.4962708950042725\n",
      "Epoch 0 :: Iteration 24/469 :: Training/Loss = 3.496558904647827\n",
      "Epoch 0 :: Iteration 25/469 :: Training/Loss = 3.4963884353637695\n",
      "Epoch 0 :: Iteration 26/469 :: Training/Loss = 3.496469259262085\n",
      "Epoch 0 :: Iteration 27/469 :: Training/Loss = 3.4966790676116943\n",
      "Epoch 0 :: Iteration 28/469 :: Training/Loss = 3.4967236518859863\n",
      "Epoch 0 :: Iteration 29/469 :: Training/Loss = 3.496358871459961\n",
      "Epoch 0 :: Iteration 30/469 :: Training/Loss = 3.4964218139648438\n",
      "Epoch 0 :: Iteration 31/469 :: Training/Loss = 3.4965946674346924\n",
      "Epoch 0 :: Iteration 32/469 :: Training/Loss = 3.4963653087615967\n",
      "Epoch 0 :: Iteration 33/469 :: Training/Loss = 3.4965298175811768\n",
      "Epoch 0 :: Iteration 34/469 :: Training/Loss = 3.4964394569396973\n",
      "Epoch 0 :: Iteration 35/469 :: Training/Loss = 3.496490240097046\n",
      "Epoch 0 :: Iteration 36/469 :: Training/Loss = 3.496600389480591\n",
      "Epoch 0 :: Iteration 37/469 :: Training/Loss = 3.496403455734253\n",
      "Epoch 0 :: Iteration 38/469 :: Training/Loss = 3.4965012073516846\n",
      "Epoch 0 :: Iteration 39/469 :: Training/Loss = 3.496424436569214\n",
      "Epoch 0 :: Iteration 40/469 :: Training/Loss = 3.496589422225952\n",
      "Epoch 0 :: Iteration 41/469 :: Training/Loss = 3.4965898990631104\n",
      "Epoch 0 :: Iteration 42/469 :: Training/Loss = 3.4967451095581055\n",
      "Epoch 0 :: Iteration 43/469 :: Training/Loss = 3.4965429306030273\n",
      "Epoch 0 :: Iteration 44/469 :: Training/Loss = 3.496500253677368\n",
      "Epoch 0 :: Iteration 45/469 :: Training/Loss = 3.4964489936828613\n",
      "Epoch 0 :: Iteration 46/469 :: Training/Loss = 3.496523141860962\n",
      "Epoch 0 :: Iteration 47/469 :: Training/Loss = 3.4966814517974854\n",
      "Epoch 0 :: Iteration 48/469 :: Training/Loss = 3.49656081199646\n",
      "Epoch 0 :: Iteration 49/469 :: Training/Loss = 3.496643543243408\n",
      "Epoch 0 :: Iteration 50/469 :: Training/Loss = 3.496523141860962\n",
      "Epoch 0 :: Iteration 51/469 :: Training/Loss = 3.4963769912719727\n",
      "Epoch 0 :: Iteration 52/469 :: Training/Loss = 3.4965322017669678\n",
      "Epoch 0 :: Iteration 53/469 :: Training/Loss = 3.4966542720794678\n",
      "Epoch 0 :: Iteration 54/469 :: Training/Loss = 3.496677875518799\n",
      "Epoch 0 :: Iteration 55/469 :: Training/Loss = 3.4967033863067627\n",
      "Epoch 0 :: Iteration 56/469 :: Training/Loss = 3.496565103530884\n",
      "Epoch 0 :: Iteration 57/469 :: Training/Loss = 3.4964566230773926\n",
      "Epoch 0 :: Iteration 58/469 :: Training/Loss = 3.4964897632598877\n",
      "Epoch 0 :: Iteration 59/469 :: Training/Loss = 3.4964094161987305\n",
      "Epoch 0 :: Iteration 60/469 :: Training/Loss = 3.4966752529144287\n",
      "Epoch 0 :: Iteration 61/469 :: Training/Loss = 3.496530294418335\n",
      "Epoch 0 :: Iteration 62/469 :: Training/Loss = 3.496626853942871\n",
      "Epoch 0 :: Iteration 63/469 :: Training/Loss = 3.4966347217559814\n",
      "Epoch 0 :: Iteration 64/469 :: Training/Loss = 3.4967432022094727\n",
      "Epoch 0 :: Iteration 65/469 :: Training/Loss = 3.4963886737823486\n",
      "Epoch 0 :: Iteration 66/469 :: Training/Loss = 3.4966113567352295\n",
      "Epoch 0 :: Iteration 67/469 :: Training/Loss = 3.4965078830718994\n",
      "Epoch 0 :: Iteration 68/469 :: Training/Loss = 3.496504783630371\n",
      "Epoch 0 :: Iteration 69/469 :: Training/Loss = 3.4963884353637695\n",
      "Epoch 0 :: Iteration 70/469 :: Training/Loss = 3.496501922607422\n",
      "Epoch 0 :: Iteration 71/469 :: Training/Loss = 3.4965081214904785\n",
      "Epoch 0 :: Iteration 72/469 :: Training/Loss = 3.496504068374634\n",
      "Epoch 0 :: Iteration 73/469 :: Training/Loss = 3.4963760375976562\n",
      "Epoch 0 :: Iteration 74/469 :: Training/Loss = 3.4967546463012695\n",
      "Epoch 0 :: Iteration 75/469 :: Training/Loss = 3.4966650009155273\n",
      "Epoch 0 :: Iteration 76/469 :: Training/Loss = 3.4964189529418945\n",
      "Epoch 0 :: Iteration 77/469 :: Training/Loss = 3.496340036392212\n",
      "Epoch 0 :: Iteration 78/469 :: Training/Loss = 3.4963834285736084\n",
      "Epoch 0 :: Iteration 79/469 :: Training/Loss = 3.4964253902435303\n",
      "Epoch 0 :: Iteration 80/469 :: Training/Loss = 3.496551990509033\n",
      "Epoch 0 :: Iteration 81/469 :: Training/Loss = 3.4962716102600098\n",
      "Epoch 0 :: Iteration 82/469 :: Training/Loss = 3.496593713760376\n",
      "Epoch 0 :: Iteration 83/469 :: Training/Loss = 3.4965004920959473\n",
      "Epoch 0 :: Iteration 84/469 :: Training/Loss = 3.4963715076446533\n",
      "Epoch 0 :: Iteration 85/469 :: Training/Loss = 3.496501922607422\n",
      "Epoch 0 :: Iteration 86/469 :: Training/Loss = 3.4965779781341553\n",
      "Epoch 0 :: Iteration 87/469 :: Training/Loss = 3.4966020584106445\n",
      "Epoch 0 :: Iteration 88/469 :: Training/Loss = 3.496476173400879\n",
      "Epoch 0 :: Iteration 89/469 :: Training/Loss = 3.496835947036743\n",
      "Epoch 0 :: Iteration 90/469 :: Training/Loss = 3.4963338375091553\n",
      "Epoch 0 :: Iteration 91/469 :: Training/Loss = 3.4966042041778564\n",
      "Epoch 0 :: Iteration 92/469 :: Training/Loss = 3.4966273307800293\n",
      "Epoch 0 :: Iteration 93/469 :: Training/Loss = 3.4965906143188477\n",
      "Epoch 0 :: Iteration 94/469 :: Training/Loss = 3.496368646621704\n",
      "Epoch 0 :: Iteration 95/469 :: Training/Loss = 3.496494770050049\n",
      "Epoch 0 :: Iteration 96/469 :: Training/Loss = 3.496234178543091\n",
      "Epoch 0 :: Iteration 97/469 :: Training/Loss = 3.496720314025879\n",
      "Epoch 0 :: Iteration 98/469 :: Training/Loss = 3.49656343460083\n",
      "Epoch 0 :: Iteration 99/469 :: Training/Loss = 3.496389865875244\n",
      "Epoch 0 :: Iteration 100/469 :: Training/Loss = 3.4964182376861572\n",
      "Epoch 0 :: Iteration 101/469 :: Training/Loss = 3.4967613220214844\n",
      "Epoch 0 :: Iteration 102/469 :: Training/Loss = 3.49661922454834\n",
      "Epoch 0 :: Iteration 103/469 :: Training/Loss = 3.496394634246826\n",
      "Epoch 0 :: Iteration 104/469 :: Training/Loss = 3.4963691234588623\n",
      "Epoch 0 :: Iteration 105/469 :: Training/Loss = 3.496333122253418\n",
      "Epoch 0 :: Iteration 106/469 :: Training/Loss = 3.4966676235198975\n",
      "Epoch 0 :: Iteration 107/469 :: Training/Loss = 3.4964048862457275\n",
      "Epoch 0 :: Iteration 108/469 :: Training/Loss = 3.496962547302246\n",
      "Epoch 0 :: Iteration 109/469 :: Training/Loss = 3.496372699737549\n",
      "Epoch 0 :: Iteration 110/469 :: Training/Loss = 3.4966373443603516\n",
      "Epoch 0 :: Iteration 111/469 :: Training/Loss = 3.496659517288208\n",
      "Epoch 0 :: Iteration 112/469 :: Training/Loss = 3.4966037273406982\n",
      "Epoch 0 :: Iteration 113/469 :: Training/Loss = 3.4965388774871826\n",
      "Epoch 0 :: Iteration 114/469 :: Training/Loss = 3.4965178966522217\n",
      "Epoch 0 :: Iteration 115/469 :: Training/Loss = 3.4964373111724854\n",
      "Epoch 0 :: Iteration 116/469 :: Training/Loss = 3.4968159198760986\n",
      "Epoch 0 :: Iteration 117/469 :: Training/Loss = 3.4966039657592773\n",
      "Epoch 0 :: Iteration 118/469 :: Training/Loss = 3.4967997074127197\n",
      "Epoch 0 :: Iteration 119/469 :: Training/Loss = 3.4963748455047607\n",
      "Epoch 0 :: Iteration 120/469 :: Training/Loss = 3.4966864585876465\n",
      "Epoch 0 :: Iteration 121/469 :: Training/Loss = 3.4962081909179688\n",
      "Epoch 0 :: Iteration 122/469 :: Training/Loss = 3.496795892715454\n",
      "Epoch 0 :: Iteration 123/469 :: Training/Loss = 3.4965741634368896\n",
      "Epoch 0 :: Iteration 124/469 :: Training/Loss = 3.496285915374756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :: Iteration 125/469 :: Training/Loss = 3.496286153793335\n",
      "Epoch 0 :: Iteration 126/469 :: Training/Loss = 3.4959495067596436\n",
      "Epoch 0 :: Iteration 127/469 :: Training/Loss = 3.496436595916748\n",
      "Epoch 0 :: Iteration 128/469 :: Training/Loss = 3.497002124786377\n",
      "Epoch 0 :: Iteration 129/469 :: Training/Loss = 3.496401786804199\n",
      "Epoch 0 :: Iteration 130/469 :: Training/Loss = 3.496635913848877\n",
      "Epoch 0 :: Iteration 131/469 :: Training/Loss = 3.4966931343078613\n",
      "Epoch 0 :: Iteration 132/469 :: Training/Loss = 3.496638298034668\n",
      "Epoch 0 :: Iteration 133/469 :: Training/Loss = 3.4963302612304688\n",
      "Epoch 0 :: Iteration 134/469 :: Training/Loss = 3.4966557025909424\n",
      "Epoch 0 :: Iteration 135/469 :: Training/Loss = 3.4964370727539062\n",
      "Epoch 0 :: Iteration 136/469 :: Training/Loss = 3.4966704845428467\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 137/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 138/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 139/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 140/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 141/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 142/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 143/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 144/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 145/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 146/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 147/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 148/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 149/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 150/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 151/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 152/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 153/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 154/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 155/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 156/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 157/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 158/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 159/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 160/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 161/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 162/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 163/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 164/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 165/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 166/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 167/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 168/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 169/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 170/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 171/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 172/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 173/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 174/469 :: Training/Loss = nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Epoch 0 :: Iteration 175/469 :: Training/Loss = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2a25a8ecdf8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mnbr_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbr_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m               verbose=True)\n\u001b[0m",
      "\u001b[0;32m~/Development/git/ReferentialGym/ReferentialGym/referential_game.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, prototype_speaker, prototype_listener, nbr_epoch, logger, verbose)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mlistener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx_stimuli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstimuli\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mspeaker_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mlistener_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TORCH3.6/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "refgame.train(prototype_speaker=bspeaker, \n",
    "              prototype_listener=blistener, \n",
    "              nbr_epoch=nbr_epoch,\n",
    "              logger=logger,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
